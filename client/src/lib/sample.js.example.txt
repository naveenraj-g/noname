//   <h1>Medical Voice Assistant Client</h1>
//   <button id="startBtn">üé§ Start Recording</button>
//   <button id="stopBtn" disabled>‚èπÔ∏è Stop Recording</button>
//   <div id="messages"></div>

const wsUrl = "ws://localhost:8000/chat";
const startBtn = document.getElementById("startBtn");
const stopBtn = document.getElementById("stopBtn");
const messages = document.getElementById("messages");

let ws = null;
let audioContext = null;
let mediaStream = null;
let processor = null;
let input = null;
let chunkBuffer = [];
let chunkIntervalId = null;
const CHUNK_INTERVAL = 200;

let playbackAudioContext = null;
let audioQueue = [];
let isPlaying = false;

// ü™∂ Helper: Display text
function appendMessage(text) {
  const p = document.createElement("p");
  p.textContent = text;
  messages.appendChild(p);
  messages.scrollTop = messages.scrollHeight;
}

// üéöÔ∏è Downsample 48kHz ‚Üí 16kHz before sending
function downsampleBuffer(buffer, inputRate, targetRate) {
  if (targetRate === inputRate) return buffer;
  const ratio = inputRate / targetRate;
  const newLength = Math.round(buffer.length / ratio);
  const result = new Float32Array(newLength);
  let offset = 0;
  let pos = 0;
  while (pos < newLength) {
    const nextOffset = Math.round((pos + 1) * ratio);
    let accum = 0,
      count = 0;
    for (let i = offset; i < nextOffset && i < buffer.length; i++) {
      accum += buffer[i];
      count++;
    }
    result[pos] = accum / count;
    pos++;
    offset = nextOffset;
  }
  return result;
}

// üîä Convert Float32 ‚Üí PCM16
function floatTo16BitPCM(floatSamples) {
  const buffer = new ArrayBuffer(floatSamples.length * 2);
  const view = new DataView(buffer);
  for (let i = 0; i < floatSamples.length; i++) {
    let s = Math.max(-1, Math.min(1, floatSamples[i]));
    view.setInt16(i * 2, s < 0 ? s * 0x8000 : s * 0x7fff, true);
  }
  return buffer;
}

// üîà Play PCM16 audio chunks smoothly
async function playPCM16(arrayBuffer) {
  if (!playbackAudioContext) {
    playbackAudioContext = new (window.AudioContext ||
      window.webkitAudioContext)({ sampleRate: 16000 });
    await playbackAudioContext.resume();
  }
  if (playbackAudioContext.state === "suspended") {
    await playbackAudioContext.resume();
  }

  const int16Array = new Int16Array(arrayBuffer);
  const float32Array = new Float32Array(int16Array.length);
  for (let i = 0; i < int16Array.length; i++) {
    float32Array[i] = int16Array[i] / 32768;
  }

  audioQueue.push(float32Array);
  if (isPlaying) return;
  isPlaying = true;

  while (audioQueue.length > 0) {
    const data = audioQueue.shift();
    const buffer = playbackAudioContext.createBuffer(
      1,
      data.length,
      playbackAudioContext.sampleRate
    );
    buffer.copyToChannel(data, 0);
    const src = playbackAudioContext.createBufferSource();
    src.buffer = buffer;
    src.connect(playbackAudioContext.destination);
    await new Promise((resolve) => {
      src.onended = resolve;
      src.start();
    });
  }
  isPlaying = false;
}

// üñ±Ô∏è Resume AudioContexts (autoplay rule)
document.body.addEventListener("click", async () => {
  if (playbackAudioContext && playbackAudioContext.state === "suspended")
    await playbackAudioContext.resume();
  if (audioContext && audioContext.state === "suspended")
    await audioContext.resume();
});

// üé§ Start Recording
startBtn.onclick = async () => {
  try {
    ws = new WebSocket(wsUrl);
    ws.binaryType = "arraybuffer";

    ws.onopen = () => appendMessage("‚úÖ WebSocket connected.");
    ws.onclose = () => appendMessage("‚ùå WebSocket disconnected.");
    ws.onerror = () => appendMessage("‚ö†Ô∏è WebSocket error.");

    ws.onmessage = async (event) => {
      let buffer = null;

      if (typeof event.data === "string") {
        if (event.data === "__TTS_END__") {
          console.log("TTS finished.");
          return;
        }
        appendMessage(event.data);
      } else if (event.data instanceof Blob) {
        buffer = await event.data.arrayBuffer();
      } else if (event.data instanceof ArrayBuffer) {
        buffer = event.data;
      }

      if (buffer) await playPCM16(buffer);
    };

    // üéß Audio capture setup
    audioContext = new AudioContext({ sampleRate: 48000 }); // default input rate
    await audioContext.resume();
    mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });
    input = audioContext.createMediaStreamSource(mediaStream);

    processor = audioContext.createScriptProcessor(4096, 1, 1);
    input.connect(processor);
    processor.connect(audioContext.destination);

    processor.onaudioprocess = (e) => {
      const data = e.inputBuffer.getChannelData(0);
      const downsampled = downsampleBuffer(data, 48000, 16000);
      chunkBuffer.push(...downsampled);
    };

    chunkIntervalId = setInterval(() => {
      if (chunkBuffer.length > 0 && ws.readyState === WebSocket.OPEN) {
        const pcmBuffer = floatTo16BitPCM(chunkBuffer);
        ws.send(pcmBuffer);
        chunkBuffer = [];
      }
    }, CHUNK_INTERVAL);

    startBtn.disabled = true;
    stopBtn.disabled = false;
    appendMessage("üé§ Recording started.");
  } catch (err) {
    appendMessage("‚ùå Mic error: " + err.message);
  }
};

// ‚èπÔ∏è Stop Recording
stopBtn.onclick = () => {
  if (processor) processor.disconnect();
  if (input) input.disconnect();
  if (mediaStream) mediaStream.getTracks().forEach((t) => t.stop());
  if (audioContext) audioContext.close();
  if (chunkIntervalId) clearInterval(chunkIntervalId);
  if (ws) ws.close();

  processor = input = mediaStream = audioContext = ws = null;
  chunkIntervalId = null;
  startBtn.disabled = false;
  stopBtn.disabled = true;
  appendMessage("‚èπÔ∏è Recording stopped.");
};
